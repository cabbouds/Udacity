{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Bag of Words Meets Popcorn Part 2: Word Vectors\n",
    "\n",
    "Following: https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Distributed Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Word2Vec](https://code.google.com/archive/p/word2vec/) is a neural network that learns [distributed representations](http://www.cs.toronto.edu/~bonner/courses/2014s/csc321/lectures/lec5.pdf) for words. One big advantage of Word2Vec over similar models is it learns very quickly.\n",
    "\n",
    "Word2Vec does not need labels in order to create meaningful representations. If it is given enough data, it produces word vectors with nice characteristics - words with similar meanings appear in clusters and clusters are spaced such that some word relationships (e.g., analogies) can be reproduced by vector math (e.g., 'king - man + woman = queen').\n",
    "\n",
    "Google's papers and [this presentation](https://docs.google.com/file/d/0B7XkCwpI5KDYRWRnd1RzWXQ2TWc/edit?pref=2&pli=1) are helpful for understanding Word2Vec. Researchers at Stanford [applied deep learning to sentiment analysis](http://nlp.stanford.edu/sentiment/). This approach relies on sentence parsing and cannot be applied straightforwardly to paragraphs of arbitrary length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using word2vec in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is implemented in the `gensim` package. Word2Vec also requires `cython` to speed up the running time (from days to minutes!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use unlabeled training data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 25000 labeled, 25000 test, and 50000 unlabeled\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./labeledTrainData.tsv', header=0, delimiter='\\t', quoting=3)\n",
    "test = pd.read_csv('./testData.tsv', header=0, delimiter='\\t', quoting=3)\n",
    "unlabeled_train = pd.read_csv('./unlabeledTrainData.tsv', header=0, delimiter='\\t', quoting=3)\n",
    "\n",
    "print 'read %d labeled, %d test, and %d unlabeled' % (train['review'].size,\n",
    "                                                      test['review'].size,\n",
    "                                                      unlabeled_train['review'].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training Word2Vec, we generally want to leave stopwords in place as the algorithm uses broad context to establish word vectors. We may also wish to preserve numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no need to recompute this set for every function call\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def review_to_wordlist(review_text, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    here we will have already removed html for tokenizing into sentences\n",
    "    \"\"\"\n",
    "    # remove non-letters\n",
    "    review_text = re.sub(r'[^a-zA-Z]', ' ', review_text)\n",
    "    # convert to lower-case and split\n",
    "    words = review_text.lower().split()\n",
    "    # remove stopwords?\n",
    "    if remove_stopwords:\n",
    "        words = [w for w in words if not w in stops]\n",
    "    # return a list of words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec expects single sentences - each one as a list of words. So the input format is a list of lists. Splitting paragraphs into sentences is not simple. We will use NLTK's `punkt` tokenizer for sentence splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "\n",
    "# load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_sentences(review, tokenizer, remove_stopwords=False, parser='lxml'):\n",
    "    # remove html first\n",
    "    review_text = BeautifulSoup(review, parser).get_text()\n",
    "    # use tokenizer to split paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review_text.strip())\n",
    "    # loop over sentences...\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # skip empty\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'with',\n",
       "  u'all',\n",
       "  u'this',\n",
       "  u'stuff',\n",
       "  u'going',\n",
       "  u'down',\n",
       "  u'at',\n",
       "  u'the',\n",
       "  u'moment',\n",
       "  u'with',\n",
       "  u'mj',\n",
       "  u'i',\n",
       "  u've',\n",
       "  u'started',\n",
       "  u'listening',\n",
       "  u'to',\n",
       "  u'his',\n",
       "  u'music',\n",
       "  u'watching',\n",
       "  u'the',\n",
       "  u'odd',\n",
       "  u'documentary',\n",
       "  u'here',\n",
       "  u'and',\n",
       "  u'there',\n",
       "  u'watched',\n",
       "  u'the',\n",
       "  u'wiz',\n",
       "  u'and',\n",
       "  u'watched',\n",
       "  u'moonwalker',\n",
       "  u'again'],\n",
       " [u'maybe',\n",
       "  u'i',\n",
       "  u'just',\n",
       "  u'want',\n",
       "  u'to',\n",
       "  u'get',\n",
       "  u'a',\n",
       "  u'certain',\n",
       "  u'insight',\n",
       "  u'into',\n",
       "  u'this',\n",
       "  u'guy',\n",
       "  u'who',\n",
       "  u'i',\n",
       "  u'thought',\n",
       "  u'was',\n",
       "  u'really',\n",
       "  u'cool',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'eighties',\n",
       "  u'just',\n",
       "  u'to',\n",
       "  u'maybe',\n",
       "  u'make',\n",
       "  u'up',\n",
       "  u'my',\n",
       "  u'mind',\n",
       "  u'whether',\n",
       "  u'he',\n",
       "  u'is',\n",
       "  u'guilty',\n",
       "  u'or',\n",
       "  u'innocent'],\n",
       " [u'moonwalker',\n",
       "  u'is',\n",
       "  u'part',\n",
       "  u'biography',\n",
       "  u'part',\n",
       "  u'feature',\n",
       "  u'film',\n",
       "  u'which',\n",
       "  u'i',\n",
       "  u'remember',\n",
       "  u'going',\n",
       "  u'to',\n",
       "  u'see',\n",
       "  u'at',\n",
       "  u'the',\n",
       "  u'cinema',\n",
       "  u'when',\n",
       "  u'it',\n",
       "  u'was',\n",
       "  u'originally',\n",
       "  u'released'],\n",
       " [u'some',\n",
       "  u'of',\n",
       "  u'it',\n",
       "  u'has',\n",
       "  u'subtle',\n",
       "  u'messages',\n",
       "  u'about',\n",
       "  u'mj',\n",
       "  u's',\n",
       "  u'feeling',\n",
       "  u'towards',\n",
       "  u'the',\n",
       "  u'press',\n",
       "  u'and',\n",
       "  u'also',\n",
       "  u'the',\n",
       "  u'obvious',\n",
       "  u'message',\n",
       "  u'of',\n",
       "  u'drugs',\n",
       "  u'are',\n",
       "  u'bad',\n",
       "  u'm',\n",
       "  u'kay',\n",
       "  u'visually',\n",
       "  u'impressive',\n",
       "  u'but',\n",
       "  u'of',\n",
       "  u'course',\n",
       "  u'this',\n",
       "  u'is',\n",
       "  u'all',\n",
       "  u'about',\n",
       "  u'michael',\n",
       "  u'jackson',\n",
       "  u'so',\n",
       "  u'unless',\n",
       "  u'you',\n",
       "  u'remotely',\n",
       "  u'like',\n",
       "  u'mj',\n",
       "  u'in',\n",
       "  u'anyway',\n",
       "  u'then',\n",
       "  u'you',\n",
       "  u'are',\n",
       "  u'going',\n",
       "  u'to',\n",
       "  u'hate',\n",
       "  u'this',\n",
       "  u'and',\n",
       "  u'find',\n",
       "  u'it',\n",
       "  u'boring'],\n",
       " [u'some',\n",
       "  u'may',\n",
       "  u'call',\n",
       "  u'mj',\n",
       "  u'an',\n",
       "  u'egotist',\n",
       "  u'for',\n",
       "  u'consenting',\n",
       "  u'to',\n",
       "  u'the',\n",
       "  u'making',\n",
       "  u'of',\n",
       "  u'this',\n",
       "  u'movie',\n",
       "  u'but',\n",
       "  u'mj',\n",
       "  u'and',\n",
       "  u'most',\n",
       "  u'of',\n",
       "  u'his',\n",
       "  u'fans',\n",
       "  u'would',\n",
       "  u'say',\n",
       "  u'that',\n",
       "  u'he',\n",
       "  u'made',\n",
       "  u'it',\n",
       "  u'for',\n",
       "  u'the',\n",
       "  u'fans',\n",
       "  u'which',\n",
       "  u'if',\n",
       "  u'true',\n",
       "  u'is',\n",
       "  u'really',\n",
       "  u'nice',\n",
       "  u'of',\n",
       "  u'him',\n",
       "  u'the',\n",
       "  u'actual',\n",
       "  u'feature',\n",
       "  u'film',\n",
       "  u'bit',\n",
       "  u'when',\n",
       "  u'it',\n",
       "  u'finally',\n",
       "  u'starts',\n",
       "  u'is',\n",
       "  u'only',\n",
       "  u'on',\n",
       "  u'for',\n",
       "  u'minutes',\n",
       "  u'or',\n",
       "  u'so',\n",
       "  u'excluding',\n",
       "  u'the',\n",
       "  u'smooth',\n",
       "  u'criminal',\n",
       "  u'sequence',\n",
       "  u'and',\n",
       "  u'joe',\n",
       "  u'pesci',\n",
       "  u'is',\n",
       "  u'convincing',\n",
       "  u'as',\n",
       "  u'a',\n",
       "  u'psychopathic',\n",
       "  u'all',\n",
       "  u'powerful',\n",
       "  u'drug',\n",
       "  u'lord'],\n",
       " [u'why',\n",
       "  u'he',\n",
       "  u'wants',\n",
       "  u'mj',\n",
       "  u'dead',\n",
       "  u'so',\n",
       "  u'bad',\n",
       "  u'is',\n",
       "  u'beyond',\n",
       "  u'me'],\n",
       " [u'because', u'mj', u'overheard', u'his', u'plans'],\n",
       " [u'nah',\n",
       "  u'joe',\n",
       "  u'pesci',\n",
       "  u's',\n",
       "  u'character',\n",
       "  u'ranted',\n",
       "  u'that',\n",
       "  u'he',\n",
       "  u'wanted',\n",
       "  u'people',\n",
       "  u'to',\n",
       "  u'know',\n",
       "  u'it',\n",
       "  u'is',\n",
       "  u'he',\n",
       "  u'who',\n",
       "  u'is',\n",
       "  u'supplying',\n",
       "  u'drugs',\n",
       "  u'etc',\n",
       "  u'so',\n",
       "  u'i',\n",
       "  u'dunno',\n",
       "  u'maybe',\n",
       "  u'he',\n",
       "  u'just',\n",
       "  u'hates',\n",
       "  u'mj',\n",
       "  u's',\n",
       "  u'music',\n",
       "  u'lots',\n",
       "  u'of',\n",
       "  u'cool',\n",
       "  u'things',\n",
       "  u'in',\n",
       "  u'this',\n",
       "  u'like',\n",
       "  u'mj',\n",
       "  u'turning',\n",
       "  u'into',\n",
       "  u'a',\n",
       "  u'car',\n",
       "  u'and',\n",
       "  u'a',\n",
       "  u'robot',\n",
       "  u'and',\n",
       "  u'the',\n",
       "  u'whole',\n",
       "  u'speed',\n",
       "  u'demon',\n",
       "  u'sequence'],\n",
       " [u'also',\n",
       "  u'the',\n",
       "  u'director',\n",
       "  u'must',\n",
       "  u'have',\n",
       "  u'had',\n",
       "  u'the',\n",
       "  u'patience',\n",
       "  u'of',\n",
       "  u'a',\n",
       "  u'saint',\n",
       "  u'when',\n",
       "  u'it',\n",
       "  u'came',\n",
       "  u'to',\n",
       "  u'filming',\n",
       "  u'the',\n",
       "  u'kiddy',\n",
       "  u'bad',\n",
       "  u'sequence',\n",
       "  u'as',\n",
       "  u'usually',\n",
       "  u'directors',\n",
       "  u'hate',\n",
       "  u'working',\n",
       "  u'with',\n",
       "  u'one',\n",
       "  u'kid',\n",
       "  u'let',\n",
       "  u'alone',\n",
       "  u'a',\n",
       "  u'whole',\n",
       "  u'bunch',\n",
       "  u'of',\n",
       "  u'them',\n",
       "  u'performing',\n",
       "  u'a',\n",
       "  u'complex',\n",
       "  u'dance',\n",
       "  u'scene',\n",
       "  u'bottom',\n",
       "  u'line',\n",
       "  u'this',\n",
       "  u'movie',\n",
       "  u'is',\n",
       "  u'for',\n",
       "  u'people',\n",
       "  u'who',\n",
       "  u'like',\n",
       "  u'mj',\n",
       "  u'on',\n",
       "  u'one',\n",
       "  u'level',\n",
       "  u'or',\n",
       "  u'another',\n",
       "  u'which',\n",
       "  u'i',\n",
       "  u'think',\n",
       "  u'is',\n",
       "  u'most',\n",
       "  u'people'],\n",
       " [u'if', u'not', u'then', u'stay', u'away'],\n",
       " [u'it',\n",
       "  u'does',\n",
       "  u'try',\n",
       "  u'and',\n",
       "  u'give',\n",
       "  u'off',\n",
       "  u'a',\n",
       "  u'wholesome',\n",
       "  u'message',\n",
       "  u'and',\n",
       "  u'ironically',\n",
       "  u'mj',\n",
       "  u's',\n",
       "  u'bestest',\n",
       "  u'buddy',\n",
       "  u'in',\n",
       "  u'this',\n",
       "  u'movie',\n",
       "  u'is',\n",
       "  u'a',\n",
       "  u'girl'],\n",
       " [u'michael',\n",
       "  u'jackson',\n",
       "  u'is',\n",
       "  u'truly',\n",
       "  u'one',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'most',\n",
       "  u'talented',\n",
       "  u'people',\n",
       "  u'ever',\n",
       "  u'to',\n",
       "  u'grace',\n",
       "  u'this',\n",
       "  u'planet',\n",
       "  u'but',\n",
       "  u'is',\n",
       "  u'he',\n",
       "  u'guilty'],\n",
       " [u'well',\n",
       "  u'with',\n",
       "  u'all',\n",
       "  u'the',\n",
       "  u'attention',\n",
       "  u'i',\n",
       "  u've',\n",
       "  u'gave',\n",
       "  u'this',\n",
       "  u'subject',\n",
       "  u'hmmm',\n",
       "  u'well',\n",
       "  u'i',\n",
       "  u'don',\n",
       "  u't',\n",
       "  u'know',\n",
       "  u'because',\n",
       "  u'people',\n",
       "  u'can',\n",
       "  u'be',\n",
       "  u'different',\n",
       "  u'behind',\n",
       "  u'closed',\n",
       "  u'doors',\n",
       "  u'i',\n",
       "  u'know',\n",
       "  u'this',\n",
       "  u'for',\n",
       "  u'a',\n",
       "  u'fact'],\n",
       " [u'he',\n",
       "  u'is',\n",
       "  u'either',\n",
       "  u'an',\n",
       "  u'extremely',\n",
       "  u'nice',\n",
       "  u'but',\n",
       "  u'stupid',\n",
       "  u'guy',\n",
       "  u'or',\n",
       "  u'one',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'most',\n",
       "  u'sickest',\n",
       "  u'liars'],\n",
       " [u'i', u'hope', u'he', u'is', u'not', u'the', u'latter']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_sentences(train['review'][0], tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may apply this function to prepare our data for input to Word2Vec (it will take a few minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences for training set\n",
      "Parsing sentences for unlabeled training set\n"
     ]
    }
   ],
   "source": [
    "# note we use `+=` to append lists of lists because `append()` in this case will only get the first list\n",
    "# from the second list of lists...\n",
    "\n",
    "sentences = []\n",
    "print 'Parsing sentences for training set'\n",
    "for review in train['review']:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "    \n",
    "print 'Parsing sentences for unlabeled training set'\n",
    "for review in unlabeled_train['review']:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797215\n"
     ]
    }
   ],
   "source": [
    "print len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'with', u'all', u'this', u'stuff', u'going', u'down', u'at', u'the', u'moment', u'with', u'mj', u'i', u've', u'started', u'listening', u'to', u'his', u'music', u'watching', u'the', u'odd', u'documentary', u'here', u'and', u'there', u'watched', u'the', u'wiz', u'and', u'watched', u'moonwalker', u'again']\n"
     ]
    }
   ],
   "source": [
    "print sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Saving Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to look at the Word2Vec [API documentation](http://radimrehurek.com/gensim/models/word2vec.html) in `gensim`, and at the [Google documentation](https://code.google.com/archive/p/word2vec/).\n",
    "\n",
    "* architecture: skip-gram, continuous bag of words\n",
    "* training algorithm: hierarchical softmax or negative sampling\n",
    "* downsampling of frequent words: Google recommends between 0.00001 and 0.001\n",
    "* word vector dimensionality\n",
    "* context / window size\n",
    "* worker threads\n",
    "* minimum word count\n",
    "\n",
    "Choosing parameters is subtle, but with parameters in hand, the model is easy to build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300     # word vector dimensionality\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count=min_word_count,\n",
    "                         window=context, sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we don't plan any further training, this will improve memory efficiency:\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's save the model with a meaningful name - we can load it later with `Word2Vec.load()`\n",
    "model_name = '300features_40minwords_10context'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `doesnt_match()` will try to deduce which word in a set is most dissimilar\n",
    "model.doesnt_match('man woman child kitchen'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match('france england germany berlin'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with small training set, this isn't perfect...\n",
    "model.doesnt_match('paris berlin london austria'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'woman', 0.6359847187995911),\n",
       " (u'guy', 0.5018903017044067),\n",
       " (u'person', 0.4842371344566345),\n",
       " (u'girl', 0.4584445357322693),\n",
       " (u'boy', 0.45680925250053406),\n",
       " (u'lady', 0.45362645387649536),\n",
       " (u'men', 0.4079422950744629),\n",
       " (u'he', 0.39524075388908386),\n",
       " (u'himself', 0.3905450105667114),\n",
       " (u'kid', 0.3840121030807495)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'princess', 0.5241572260856628),\n",
       " (u'latifah', 0.4557710886001587),\n",
       " (u'bee', 0.454694926738739),\n",
       " (u'victoria', 0.4427083134651184),\n",
       " (u'prince', 0.4377889037132263),\n",
       " (u'king', 0.43018147349357605),\n",
       " (u'margaret', 0.38042858242988586),\n",
       " (u'stepmother', 0.37996935844421387),\n",
       " (u'selena', 0.3768102824687958),\n",
       " (u'maid', 0.3498295545578003)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'terrible', 0.6530819535255432),\n",
       " (u'horrible', 0.6271060705184937),\n",
       " (u'dreadful', 0.5867845416069031),\n",
       " (u'atrocious', 0.5674465894699097),\n",
       " (u'abysmal', 0.5667630434036255),\n",
       " (u'laughable', 0.5436089634895325),\n",
       " (u'horrendous', 0.5300754308700562),\n",
       " (u'embarrassing', 0.5102269649505615),\n",
       " (u'appalling', 0.5048348903656006),\n",
       " (u'amateurish', 0.498172402381897)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for sentiment analysis...\n",
    "model.most_similar('awful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
