{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2: Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Parameters Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Screen_Shot_2016-02-15_at_8.27.37_AM.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7850\n"
     ]
    }
   ],
   "source": [
    "W_n_in = 28 * 28 \n",
    "W_n_out = 10\n",
    "n_W = W_n_in * W_n_out\n",
    "n_bias = 10\n",
    "n_total = n_bias + n_W\n",
    "print(n_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models are Limited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Screen_Shot_2016-02-15_at_8.36.02_AM.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, linear models, are, well, _linear_. We cannot represent certain types of outcomes. But, linear models are efficient and stable! The derivatives are really nice too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectified Linear Units (ReLU) Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice derivative..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Network of ReLUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum change: add a layer of $H$ ReLUs in the \"middle\" of our network. So now we have two sets of weights and biases, with a layer of ReLUs in between:\n",
    "\n",
    "<img src='Screen_Shot_2016-02-16_at_8.12.29_AM.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Neuromorphic engineering\" - great phrase, and it might even be true. But it comes with a lot of baggage. So we are going to avoid that sort of language here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chain Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build our network by stacking simple operations. This allows us to employ the chain rule:\n",
    "\n",
    "\\begin{equation}\n",
    "[g(f(x))]' = g'(f(x)) \\times f'(x)\n",
    "\\end{equation}\n",
    "\n",
    "We may represent this in a _graph_:\n",
    "\n",
    "<img src='Screen_Shot_2016-02-16_at_8.18.58_AM.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Screen_Shot_2016-02-16_at_8.21.10_AM.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure:\n",
    "\n",
    "1. run the forward prop\n",
    "2. run the back prop\n",
    "3. update weights according to $W_i \\to W_i - \\alpha \\Delta W_i$\n",
    "4. go back to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each block of the back prop usually takes about twice the memory as the corresponding block in the forward prop, and twice the compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segue into Assignment 2: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training a Deep Learning Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep networks have several advantages over \"wide\" networks:\n",
    "\n",
    "1. parameter efficiency - better performance with fewer parameters by going deeper rather than wider\n",
    "2. deep models naturally capture hierarchical structure (lower levels find line edges, higher levels find parts, final levels identify objects)\n",
    "\n",
    "<img src='Screen_Shot_2016-02-17_at_8.36.12_AM.png'>\n",
    "<img src='Screen_Shot_2016-02-17_at_8.38.21_AM.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
